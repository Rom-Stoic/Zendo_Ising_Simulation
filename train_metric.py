import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import os
import argparse
from torch_geometric.loader import DataLoader
from torch_geometric.data import Batch

from world import KoanAtlas
from dataset import ZendoGraphDataset, KoanSampler
from model import ZendoNet
from config import Config

def train(epochs=50, batch_size=64):
    print("ğŸš€ [Train] åˆå§‹åŒ–è®­ç»ƒç¯å¢ƒ...")
    
    # 1. å‡†å¤‡æ•°æ®
    atlas = KoanAtlas()
    dataset = ZendoGraphDataset(atlas)
    sampler = KoanSampler(atlas) # æ„å»ºç´¢å¼•
    
    # 2. æ¨¡å‹ä¸ä¼˜åŒ–å™¨
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = ZendoNet().to(device)
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    
    # Triplet Margin Loss
    # ä½¿å¾— D(A, P) + margin < D(A, N)
    criterion = nn.TripletMarginLoss(margin=1.0, p=2)
    
    attributes = ['color', 'size', 'ground', 'structure']
    
    print(f"ğŸ”¥ [Train] å¼€å§‹è®­ç»ƒ (Device: {device})...")
    model.train()
    
    for epoch in range(epochs):
        total_loss = 0
        steps = 0
        
        # æ¯ä¸ª Epoch éšæœºæŒ–æ˜ 100 ä¸ª Batch
        num_batches = 100 
        
        for _ in range(num_batches):
            batch_loss = 0
            optimizer.zero_grad()
            
            # å¯¹æ¯ä¸ªå±æ€§å¤´åˆ†åˆ«è¿›è¡Œè®­ç»ƒ
            for attr in attributes:
                # A. æŒ–æ˜ä¸‰å…ƒç»„ç´¢å¼•
                a_idx, p_idx, n_idx = sampler.get_triplet_batch(attr, batch_size)
                
                # B. æ„å»º Batch å›¾æ•°æ®
                # å°†ç´¢å¼•è½¬æ¢ä¸º Dataset ä¸­çš„ Data å¯¹è±¡åˆ—è¡¨ï¼Œå† collate æˆ Batch
                batch_a = Batch.from_data_list([dataset.get(i) for i in a_idx]).to(device)
                batch_p = Batch.from_data_list([dataset.get(i) for i in p_idx]).to(device)
                batch_n = Batch.from_data_list([dataset.get(i) for i in n_idx]).to(device)
                
                # C. å‰å‘ä¼ æ’­
                out_a = model(batch_a)[attr]
                out_p = model(batch_p)[attr]
                out_n = model(batch_n)[attr]
                
                # D. è®¡ç®—æŸå¤±
                loss = criterion(out_a, out_p, out_n)
                batch_loss += loss
            
            # E. åå‘ä¼ æ’­ (ç´¯ç§¯äº†4ä¸ªå¤´çš„ Loss)
            batch_loss.backward()
            optimizer.step()
            
            total_loss += batch_loss.item()
            steps += 1
            
        avg_loss = total_loss / steps
        print(f"Epoch {epoch+1}/{epochs} | Loss: {avg_loss:.4f}")
        
    # ä¿å­˜æ¨¡å‹
    if not os.path.exists("models"): os.makedirs("models")
    torch.save(model.state_dict(), "models/zendonet_metric.pth")
    print("ğŸ’¾ æ¨¡å‹å·²ä¿å­˜è‡³ models/zendonet_metric.pth")

def run_inference():
    """
    åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå¯¹å®‡å®™ä¸­æ‰€æœ‰å…¬æ¡ˆè¿›è¡Œç¼–ç ï¼Œå¹¶ä¿å­˜ä¸º .npy æ–‡ä»¶
    """
    print("ğŸ”® [Inference] å¼€å§‹å…¨é‡æ¨ç†...")
    
    atlas = KoanAtlas()
    dataset = ZendoGraphDataset(atlas)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = ZendoNet().to(device)
    
    model_path = "models/zendonet_metric.pth"
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path, map_location=device))
        print("âœ… å·²åŠ è½½é¢„è®­ç»ƒæ¨¡å‹")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–æ¨¡å‹è¿›è¡Œæµ‹è¯•...")
    
    model.eval()
    
    # æ„é€ å…¨é‡ Batch
    # æ³¨æ„ï¼šå¦‚æœæ˜¾å­˜ä¸å¤Ÿï¼Œè¿™é‡Œéœ€è¦åˆ†æ‰¹æ¬¡ (DataLoader)
    print("ğŸ“¦ æ­£åœ¨æ‰“åŒ…æ‰€æœ‰æ•°æ®...")
    loader = DataLoader(dataset, batch_size=128, shuffle=False)
    
    emb_c, emb_s, emb_g, emb_t = [], [], [], []
    
    with torch.no_grad():
        for batch in loader:
            batch = batch.to(device)
            out = model(batch)
            
            emb_c.append(out['color'].detach().cpu().numpy())
            emb_s.append(out['size'].detach().cpu().numpy())
            emb_g.append(out['ground'].detach().cpu().numpy())
            emb_t.append(out['structure'].detach().cpu().numpy())
            
    # æ‹¼æ¥
    final_c = np.concatenate(emb_c, axis=0)
    final_s = np.concatenate(emb_s, axis=0)
    final_g = np.concatenate(emb_g, axis=0)
    final_t = np.concatenate(emb_t, axis=0)
    
    # ä¿å­˜
    if not os.path.exists("data"): os.makedirs("data")
    np.save("data/emb_color.npy", final_c)
    np.save("data/emb_size.npy", final_s)
    np.save("data/emb_ground.npy", final_g)
    np.save("data/emb_structure.npy", final_t)
    
    print(f"âœ… Embedding å·²ä¿å­˜è‡³ data/ ç›®å½•")
    print(f"   Color Shape: {final_c.shape}")
    print(f"   Struct Shape: {final_t.shape}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--mode', type=str, default='train', choices=['train', 'run'], help='Mode: train or run (inference)')
    args = parser.parse_args()
    
    if args.mode == 'train':
        train()
    else:
        run_inference()