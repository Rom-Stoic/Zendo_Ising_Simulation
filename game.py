import numpy as np
import torch
import time
import os  # [New] ç”¨äºæ–‡ä»¶æ“ä½œ
from tqdm import tqdm

from config import Config
from world import KoanAtlas
from physics import IsingModel
from dynamics import FastSolver, DPP, SlowLearner

class RuleEngine:
    """
    è§„åˆ™å¼•æ“ï¼šå®šä¹‰ 9 å±€æ¸¸æˆçš„ Ground Truth é€»è¾‘ã€‚
    è´Ÿè´£åˆ¤æ–­æŸä¸ªå…¬æ¡ˆæ˜¯å¦ç¬¦åˆç‰¹å®šè§„åˆ™ã€‚
    """
    def __init__(self, atlas):
        self.atlas = atlas
        self.rules = [
            ("å­˜åœ¨çº¢è‰²ç‰©ä½“", self.rule_exist_red),
            ("å°ºå¯¸å®Œå…¨ä¸€è‡´", self.rule_same_size),
            ("è“è‰²ç‰©ä½“å”¯ä¸€", self.rule_unique_blue),
            ("å­˜åœ¨è“è‰²å°ç‰©ä½“", self.rule_exist_blue_small),
            ("å…¨å‘˜è“è‰²æˆ–å°å°ºå¯¸", self.rule_all_blue_or_small),
            ("çº¢è€…æœ€å¤§", self.rule_red_is_largest),
            ("ç‰©ä½“é—´æœ‰æ¥è§¦", self.rule_contact_exists),
            ("çº¢è“ç›¸è§¦", self.rule_red_blue_contact),
            ("å­˜åœ¨å †å ç°è±¡", self.rule_stack_exists)
        ]

    def get_ground_truth_vector(self, rule_idx):
        """è®¡ç®—å…¨å®‡å®™ 5127 ä¸ªå…¬æ¡ˆåœ¨æŒ‡å®šè§„åˆ™ä¸‹çš„çœŸå€¼å‘é‡ (+1/-1)"""
        rule_name, rule_func = self.rules[rule_idx]
        print(f"\nğŸ“œ æ­£åœ¨ç¼–è¯‘è§„åˆ™ [{rule_idx+1}/9]: {rule_name} ...")
        
        gt_vector = np.zeros(self.atlas.num_koans, dtype=np.float32)
        
        for i in range(self.atlas.num_koans):
            is_true = rule_func(i)
            gt_vector[i] = 1.0 if is_true else -1.0
            
        return gt_vector, rule_name

    # --- è¾…åŠ©æå–å‡½æ•° ---
    def _get_active_feats(self, idx):
        mass = self.atlas.mass_tensor[idx]
        active = np.where(mass > 0)[0]
        feats = self.atlas.feature_tensor[idx][active]
        return feats, active

    def _get_colors(self, feats):
        # one-hot argmax: 0=R, 1=G, 2=B
        return np.argmax(feats[:, Config.IDX_COLOR], axis=1)

    def _get_sizes(self, feats):
        # one-hot argmax: 0=S, 1=M, 2=L
        return np.argmax(feats[:, Config.IDX_SIZE], axis=1)
    
    def _get_grounds(self, feats):
        # scalar: 0=Fly, 1=Ground
        return feats[:, Config.IDX_GROUND].flatten()

    # --- å…·ä½“è§„åˆ™å®ç° ---

    def rule_exist_red(self, idx):
        feats, _ = self._get_active_feats(idx)
        colors = self._get_colors(feats)
        return 0 in colors  # 0 is Red

    def rule_same_size(self, idx):
        feats, _ = self._get_active_feats(idx)
        if len(feats) == 0: return False # é˜²å¾¡æ€§ç¼–ç¨‹
        sizes = self._get_sizes(feats)
        return np.all(sizes == sizes[0])

    def rule_unique_blue(self, idx):
        feats, _ = self._get_active_feats(idx)
        colors = self._get_colors(feats)
        return np.sum(colors == 2) == 1 # 2 is Blue

    def rule_exist_blue_small(self, idx):
        feats, _ = self._get_active_feats(idx)
        colors = self._get_colors(feats)
        sizes = self._get_sizes(feats)
        # Blue is 2, Small is 0
        is_blue = (colors == 2)
        is_small = (sizes == 0)
        return np.any(is_blue & is_small)

    def rule_all_blue_or_small(self, idx):
        feats, _ = self._get_active_feats(idx)
        colors = self._get_colors(feats)
        sizes = self._get_sizes(feats)
        # (Blue OR Small) for ALL
        condition = (colors == 2) | (sizes == 0)
        return np.all(condition)

    def rule_red_is_largest(self, idx):
        # çº¢è€…æœ€å¤§ï¼šè‡³å°‘æœ‰ä¸€ä¸ªçº¢è‰²ï¼Œä¸”çº¢è‰²å°ºå¯¸ > æ‰€æœ‰éçº¢è‰²å°ºå¯¸
        feats, _ = self._get_active_feats(idx)
        colors = self._get_colors(feats)
        sizes = self._get_sizes(feats)
        
        red_mask = (colors == 0)
        non_red_mask = ~red_mask
        
        if np.sum(red_mask) == 0: return False # å¿…é¡»æœ‰çº¢è‰²
        
        # [Audit Fix] é€»è¾‘ä¿®å¤ï¼šå¦‚æœå…¨å‘˜éƒ½æ˜¯çº¢è‰²ï¼Œæ²¡æœ‰éçº¢ç‰©ä½“ï¼Œåˆ™â€œæ‰€æœ‰éçº¢ç‰©ä½“â€çš„æ¡ä»¶ç©ºç¼ºã€‚
        # è¯­ä¹‰ä¸Šï¼Œæ—¢ç„¶æ²¡æœ‰éçº¢ç‰©ä½“å¯ä»¥æ¯”çº¢è‰²å¤§ï¼Œé‚£ä¹ˆçº¢è‰²å°±æ˜¯æœ€å¤§çš„ã€‚
        if np.sum(non_red_mask) == 0: return True
        
        max_red_size = np.max(sizes[red_mask])
        max_non_red_size = np.max(sizes[non_red_mask])
        
        return max_red_size > max_non_red_size

    def rule_contact_exists(self, idx):
        # é‚»æ¥çŸ©é˜µæœ‰å€¼
        mass = self.atlas.mass_tensor[idx]
        n = int(np.sum(mass > 0))
        adj = self.atlas.structure_tensor[idx][:n, :n]
        # é‚»æ¥çŸ©é˜µæ˜¯å¯¹ç§°çš„ï¼Œå¯¹è§’çº¿ä¸º0ã€‚åªè¦sum > 0 å°±è¯´æ˜æœ‰è¾¹
        return np.sum(adj) > 0

    def rule_red_blue_contact(self, idx):
        feats, active = self._get_active_feats(idx)
        n = len(active)
        adj = self.atlas.structure_tensor[idx][:n, :n]
        colors = self._get_colors(feats) # 0=R, 2=B
        
        rows, cols = np.where(adj > 0)
        for r, c in zip(rows, cols):
            # æ£€æŸ¥è¿æ¥çš„ä¸¤ä¸ªèŠ‚ç‚¹çš„é¢œè‰²
            c1, c2 = colors[r], colors[c]
            if (c1 == 0 and c2 == 2) or (c1 == 2 and c2 == 0):
                return True
        return False

    def rule_stack_exists(self, idx):
        # å­˜åœ¨å †å ï¼šå³å­˜åœ¨ä¸€ä¸ªç‰©ä½“æ²¡æœ‰æ¥åœ° (Ground=0)
        # æ³¨æ„ï¼šdataset/config å®šä¹‰ Ground=1 ä¸ºæ¥åœ°ï¼Œ0 ä¸ºæ‚¬ç©º(å †å åœ¨åˆ«äººä¸Šé¢)
        feats, _ = self._get_active_feats(idx)
        grounds = self._get_grounds(feats)
        # å¦‚æœå­˜åœ¨ ground == 0ï¼Œè¯´æ˜æœ‰å †å 
        return np.any(grounds < 0.5)


class ZendoGame:
    def __init__(self):
        # 1. åˆå§‹åŒ–åŸºç¡€è®¾æ–½
        self.atlas = KoanAtlas()
        self.rule_engine = RuleEngine(self.atlas)
        
        # 2. æ ¸å¿ƒç»„ä»¶
        self.physics = IsingModel(self.atlas.num_koans)
        self.solver = FastSolver()
        self.dpp = DPP()
        self.learner = SlowLearner(self.atlas)
        
        # 3. [New] å®éªŒè®°å½•ç›®å½•
        self.log_dir = "hypotheses_log"
        if not os.path.exists(self.log_dir):
            os.makedirs(self.log_dir)
            print(f"ğŸ“ å·²åˆ›å»ºå®éªŒè®°å½•æ–‡ä»¶å¤¹: {self.log_dir}")

    def play_all_games(self):
        """æ‰§è¡Œæ‰€æœ‰ 9 å±€æ¸¸æˆ"""
        results = []
        for i in range(9):
            score, rule_name = self.run_single_game(rule_idx=i)
            results.append((rule_name, score))
            
        print("\n" + "="*60)
        print("ğŸ† Zendo æŒ‘æˆ˜èµ›æœ€ç»ˆæˆç»©å•")
        print("="*60)
        avg_score = 0
        for name, score in results:
            print(f"è§„åˆ™: {name:<20} | å‡†ç¡®ç‡: {score*100:.2f}%")
            avg_score += score
        print("-" * 60)
        print(f"å¹³å‡å‡†ç¡®ç‡: {(avg_score/9)*100:.2f}%")
        print("="*60)

    def run_single_game(self, rule_idx):
        # --- Game Setup ---
        gt_vector, rule_name = self.rule_engine.get_ground_truth_vector(rule_idx)
        
        print(f"\nğŸ® [GAME {rule_idx+1}] è§„åˆ™: {rule_name}")
        
        # [New] ä¸ºå½“å‰æ¸¸æˆåˆ›å»ºç‹¬ç«‹æ–‡ä»¶å¤¹
        # å¤„ç†ä¸€ä¸‹æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦
        safe_rule_name = rule_name.replace(" ", "_").replace("/", "-")
        game_log_dir = os.path.join(self.log_dir, f"Game_{rule_idx+1}_{safe_rule_name}")
        if not os.path.exists(game_log_dir):
            os.makedirs(game_log_dir)
        
        # 1. Reset State
        # é‡ç½®æ³¨æ„åŠ›ä¸ºå‡åŒ€
        current_attention = Config.INIT_ATTENTION.copy()
        
        # 2. Provide Initial Positive Example (Pinning Field Start)
        # éšæœºæ‰¾ä¸€ä¸ªæ­£ä¾‹
        pos_indices = np.where(gt_vector > 0)[0]
        neg_indices = np.where(gt_vector < 0)[0]
        
        known_pos = [np.random.choice(pos_indices)]
        known_neg = [] # åˆå§‹æ— åä¾‹
        
        print(f"   ğŸš© åˆå§‹æç¤º (æ­£ä¾‹): Koan #{known_pos[0]}")

        # --- Game Loop (7 Rounds) ---
        final_hypotheses = []
        
        for round_num in range(Config.MAX_ROUNDS - 1): # Run 0 to 8, but actually logic says 7 rounds of active test
            if round_num >= 7: break # é¢˜ç›®è¦æ±‚7è½®æ£€éªŒ

            # A. Update Physics (J & h)
            # æ ¹æ®å½“å‰æ³¨æ„åŠ›è®¡ç®—è·ç¦»ï¼Œæ›´æ–° J
            dist_matrix = self.atlas.get_weighted_distance_matrix(current_attention)
            self.physics.update_couplings(dist_matrix)
            
            # è®¾ç½®é’‰æ‰åœº
            self.physics.set_pinning_field(known_pos, known_neg, round_num)
            
            # B. Fast Dynamics (Generate Hypotheses)
            # éšæœºåˆå§‹åŒ–è‡ªæ—‹
            chains = []
            
            # [Audit Optimization] ä½¿ç”¨æ›´å¼ºçš„è¿­ä»£æ­¥æ•°ï¼Œç¡®ä¿è¦†ç›– 5127 ä¸ªå…¬æ¡ˆ
            # Config.MCMC_STEPS (1000) å¤ªå°ï¼Œè¿™é‡Œæ˜¾å¼ Override ä¸º System_Size * Sweeps (e.g., 20)
            mcmc_steps_override = self.atlas.num_koans * 20
            
            for _ in range(Config.NUM_CHAINS):
                init_spins = np.random.choice([-1.0, 1.0], size=self.atlas.num_koans)
                final_spins = self.solver.run_glauber(self.physics, init_spins, steps=mcmc_steps_override)
                chains.append(final_spins)
            
            # C. DPP Selection
            # é€‰å‡º 3 ä¸ªä»£è¡¨æ€§å‡è®¾
            selected_indices, _ = self.dpp.select_subset(chains, self.physics)
            current_hypotheses = [chains[i] for i in selected_indices]
            
            # å¦‚æœ DPP é€‰ä¸å¤Ÿ3ä¸ªï¼Œè¡¥å…¨
            while len(current_hypotheses) < 3:
                current_hypotheses.append(chains[np.random.randint(len(chains))])
            
            # --- [New] è®°å½•æœ¬è½®å‡è®¾å¹¶è®¡ç®—å‡†ç¡®ç‡ ---
            hyp_stack = np.stack(current_hypotheses) # (3, N)
            # è®¡ç®—å‡†ç¡®ç‡: ä¸ Ground Truth å¯¹æ¯”
            # å‡†ç¡®ç‡ = (Prediction == GT) çš„å¹³å‡å€¼
            accuracies = np.mean(hyp_stack == gt_vector, axis=1)
            
            acc_str = " | ".join([f"H{i}: {acc*100:.1f}%" for i, acc in enumerate(accuracies)])
            print(f"      ğŸ“Š æœ¬è½®å‡è®¾å‡†ç¡®ç‡: {acc_str}")
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            save_path = os.path.join(game_log_dir, f"round_{round_num+1}_hypotheses.npy")
            np.save(save_path, hyp_stack)
            # ------------------------------------

            # D. Experiment / Test (Build a Koan)
            # ä¸»åŠ¨å­¦ä¹ ï¼šæ‰¾åˆ° 3 ä¸ªå‡è®¾åˆ†æ­§æœ€å¤§çš„æœªçŸ¥å…¬æ¡ˆ
            # æ‰€è°“åˆ†æ­§æœ€å¤§ï¼Œå°±æ˜¯ mean(predictions) æœ€æ¥è¿‘ 0 (å³ +1 å’Œ -1 å„åŠ)
            
            # 1. æ’é™¤å·²çŸ¥å…¬æ¡ˆ
            known_set = set(known_pos) | set(known_neg)
            unknown_mask = np.ones(self.atlas.num_koans, dtype=bool)
            unknown_mask[list(known_set)] = False
            unknown_indices = np.where(unknown_mask)[0]
            
            # 2. è®¡ç®—åˆ†æ­§
            hyp_matrix = np.array(current_hypotheses) # (3, N)
            votes = np.sum(hyp_matrix, axis=0) # (N,) range [-3, 3]
            disagreement = -np.abs(votes) # ç»å¯¹å€¼è¶Šå°(è¶Šæ¥è¿‘0)ï¼Œåˆ†æ­§è¶Šå¤§
            
            # åªåœ¨æœªçŸ¥å…¬æ¡ˆä¸­æ‰¾
            best_test_idx = unknown_indices[np.argmax(disagreement[unknown_indices])]
            
            # E. Ground Truth Check
            truth = gt_vector[best_test_idx]
            is_pos = (truth > 0)
            
            if is_pos:
                known_pos.append(best_test_idx)
                result_str = "SUCCESS (ç¬¦åˆ)"
            else:
                known_neg.append(best_test_idx)
                result_str = "FAIL (ä¸ç¬¦)"
                
            print(f"   ğŸ”„ Round {round_num+1}: æ£€éªŒ Koan #{best_test_idx} -> {result_str} | å½“å‰å·²çŸ¥: {len(known_pos)}æ­£/{len(known_neg)}å")

            # F. Slow Dynamics (Update Attention)
            # [Audit Fix] æ˜¾å¼é€‰æ‹©èƒ½é‡æœ€ä½çš„å‡è®¾ç”¨äºå­¦ä¹ ï¼Œè€Œéç®€å•çš„åˆ—è¡¨ç¬¬ä¸€ä¸ª
            # èƒ½é‡è¶Šä½ï¼Œè¯´æ˜è¶Šç¬¦åˆå½“å‰çš„ç‰©ç†çº¦æŸå’Œè§‚æµ‹æ•°æ®
            best_h = min(current_hypotheses, key=lambda h: self.physics.compute_energy(h))
            
            current_attention = self.learner.update_attention(current_attention, best_h, self.physics)
            
            # print(f"      ğŸ§  Attention Updated: Color={current_attention[0]:.2f}, Size={current_attention[1]:.2f}, ...")

        # --- Final Evolution (Round 8 Logic) ---
        print("   âš¡ æ‰§è¡Œæœ€ç»ˆåŠ¨åŠ›å­¦æ¼”åŒ–...")
        
        # 1. Update Physics one last time
        dist_matrix = self.atlas.get_weighted_distance_matrix(current_attention)
        self.physics.update_couplings(dist_matrix)
        self.physics.set_pinning_field(known_pos, known_neg, round_num=7)
        
        # 2. Generate Final 3 Hypotheses
        chains = []
        mcmc_steps_override = self.atlas.num_koans * 20  # [Audit Fix] ä¿æŒä¸€è‡´çš„é«˜æ­¥æ•°
        
        for _ in range(Config.NUM_CHAINS):
            init_spins = np.random.choice([-1.0, 1.0], size=self.atlas.num_koans)
            final_spins = self.solver.run_glauber(self.physics, init_spins, steps=mcmc_steps_override)
            chains.append(final_spins)
            
        selected_indices, _ = self.dpp.select_subset(chains, self.physics)
        final_3_hypotheses = [chains[i] for i in selected_indices]
         # è¡¥å…¨
        while len(final_3_hypotheses) < 3:
            final_3_hypotheses.append(chains[np.random.randint(len(chains))])
            
        # --- [New] è®°å½•æœ€ç»ˆè½®æ¬¡å‡è®¾ ---
        final_stack = np.stack(final_3_hypotheses)
        final_accs = np.mean(final_stack == gt_vector, axis=1)
        acc_str = " | ".join([f"H{i}: {acc*100:.1f}%" for i, acc in enumerate(final_accs)])
        print(f"      ğŸ“Š æœ€ç»ˆå‡è®¾é›†å‡†ç¡®ç‡: {acc_str}")
        
        np.save(os.path.join(game_log_dir, "round_final_hypotheses.npy"), final_stack)
        # ----------------------------

        # 3. Merge (Voting)
        # å°†3ä¸ªå‡è®¾åˆå¹¶ä¸º1ä¸ªç»ˆæå‡è®¾
        # Rule: Majority Vote. If sum > 0 then +1, else -1
        hyp_stack = np.stack(final_3_hypotheses) # (3, N)
        sum_votes = np.sum(hyp_stack, axis=0)
        ultimate_hypothesis = np.sign(sum_votes)
        # Fix sign(0) case (unlikely but possible) -> default to -1 or random
        ultimate_hypothesis[ultimate_hypothesis == 0] = -1.0
        
        # --- [New] è®°å½•ç»ˆæå‡è®¾ ---
        np.save(os.path.join(game_log_dir, "ultimate_hypothesis.npy"), ultimate_hypothesis)
        # ------------------------

        # 4. Calculate Accuracy
        # Accuracy = (TP + TN) / Total
        matches = (ultimate_hypothesis == gt_vector)
        accuracy = np.mean(matches)
        
        print(f"   ğŸ¯ ç»ˆææŠ•ç¥¨å‡è®¾å‡†ç¡®ç‡: {accuracy*100:.2f}%")
        
        return accuracy, rule_name

if __name__ == "__main__":
    game = ZendoGame()
    game.play_all_games()